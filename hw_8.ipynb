{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JHaGLFB8gN33"
      },
      "outputs": [],
      "source": [
        "!pip install datasets transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import BertTokenizer\n",
        "import torch\n",
        "from transformers import BertForSequenceClassification, AdamW\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "import random"
      ],
      "metadata": {
        "id": "2ZE1dVKWg5vO"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " torch.manual_seed(2023)"
      ],
      "metadata": {
        "id": "bx8cybdplDTj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Подготовка данных**"
      ],
      "metadata": {
        "id": "MEnsltOhiOIp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\"imdb\")"
      ],
      "metadata": {
        "id": "7N7ubmPxiMjx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "metadata": {
        "id": "IqAeYzKiiMmd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_batch(batch):\n",
        "    return tokenizer(batch[\"text\"], padding=True, truncation=True)"
      ],
      "metadata": {
        "id": "gmTa3UeViMoO"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, test_data = train_test_split(dataset['train'].select(range(5001)), test_size=0.2)\n",
        "train_data_enc = tokenize_batch(train_data)\n",
        "test_data_enc = tokenize_batch(test_data)"
      ],
      "metadata": {
        "id": "CTN3ON5AlbLw"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**обучение учителя (трансформера)**"
      ],
      "metadata": {
        "id": "AvFWTSiwiYNR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SDC5iJNCiWdf",
        "outputId": "665ed876-6377-4006-8a88-95cffcf8a4f9"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_teacher = BertForSequenceClassification.from_pretrained('bert-base-uncased').to(device)\n",
        "optimizer_teacher = AdamW(model_teacher.parameters(), lr=2e-5)\n",
        "\n",
        "train_dataset = TensorDataset(\n",
        "    torch.tensor(train_data_enc[\"input_ids\"]),\n",
        "    torch.tensor(train_data_enc[\"attention_mask\"]),\n",
        "    torch.tensor(train_data[\"label\"])\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)"
      ],
      "metadata": {
        "id": "fQOl0LwKiWf0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_teacher.train()\n",
        "for epoch in range(3):\n",
        "    progress_bar = tqdm(train_loader, desc=f'Epoch {epoch + 1}/{3}', leave=False)\n",
        "    for batch in progress_bar:\n",
        "        input_ids, attention_mask, labels = batch\n",
        "        input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
        "\n",
        "        optimizer_teacher.zero_grad()\n",
        "        outputs = model_teacher(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "        optimizer_teacher.step()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ItOCsgYmiWiK",
        "outputId": "18f2daa3-f727-4482-f74b-90b878614bf2"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Обучение ученика LSTM**"
      ],
      "metadata": {
        "id": "q2cRaQ8ninaq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleLSTM(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(SimpleLSTM, self).__init__()\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.lstm = nn.LSTM(hidden_size, hidden_size, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        embedded = self.embedding(x)\n",
        "        output, _ = self.lstm(embedded)\n",
        "        output = self.fc(output[:, -1, :])\n",
        "        return output"
      ],
      "metadata": {
        "id": "uAkWiFfwiWkY"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_enc_lstm = tokenizer(train_data[\"text\"], return_tensors=\"pt\", padding=True, truncation=True)\n",
        "train_labels_lstm = torch.tensor(train_data[\"label\"])"
      ],
      "metadata": {
        "id": "IlgTMhbZiqUD"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset_lstm = TensorDataset(\n",
        "    train_data_enc_lstm[\"input_ids\"],\n",
        "    train_data_enc_lstm[\"attention_mask\"],\n",
        "    train_labels_lstm\n",
        ")\n",
        "\n",
        "train_loader_lstm = DataLoader(train_dataset_lstm, batch_size=8, shuffle=True, drop_last=True)"
      ],
      "metadata": {
        "id": "4sZAtiuCv00z"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_student = SimpleLSTM(input_size=len(tokenizer), hidden_size=128, output_size=2).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer_student = optim.Adam(model_student.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "6R5C0hu5iuhk"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_student.train()\n",
        "for epoch in range(3):\n",
        "    progress_bar = tqdm(train_loader_lstm, desc=f'Epoch {epoch + 1}/{3}', leave=False)\n",
        "    for batch in progress_bar:\n",
        "        input_ids, attention_mask, labels = batch\n",
        "        input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
        "\n",
        "        optimizer_student.zero_grad()\n",
        "        outputs = model_student(input_ids)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer_student.step()\n",
        "\n",
        "        progress_bar.set_postfix(loss=loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "StSUTquoiqXH",
        "outputId": "73d09113-6f1c-4b93-ef5e-54df97c65c29"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Дистилляция модели**"
      ],
      "metadata": {
        "id": "3Kh5ID5ui5VQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def distillation_loss(logits_teacher, logits_student, temperature=1.0):\n",
        "    soft_teacher = torch.softmax(logits_teacher / temperature, dim=1)\n",
        "    soft_student = torch.softmax(logits_student / temperature, dim=1)\n",
        "    return nn.KLDivLoss()(torch.log(soft_student), soft_teacher)"
      ],
      "metadata": {
        "id": "yA_IZbsXiz9E"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_teacher.eval()\n",
        "input_ids_teacher = input_ids.to(device)\n",
        "attention_mask_teacher = attention_mask.to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    logits_teacher = model_teacher(input_ids_teacher, attention_mask=attention_mask_teacher).logits\n",
        "\n",
        "# Дистилляция по батчам\n",
        "batch_size = 8\n",
        "num_batches = len(train_loader_lstm)\n",
        "loss_distillation_total = 0.0\n",
        "\n",
        "model_student.train()\n",
        "\n",
        "for batch in tqdm(train_loader_lstm, desc='Distillation', leave=False):\n",
        "    input_ids, attention_mask, labels = batch\n",
        "    input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
        "\n",
        "    # Получение logits от ученика\n",
        "    logits_student = model_student(input_ids)\n",
        "\n",
        "    # Вычисление дистилляционной потери для текущего батча\n",
        "    loss_distillation_batch = distillation_loss(logits_teacher, logits_student)\n",
        "\n",
        "    # Суммирование потерь по батчам\n",
        "    loss_distillation_total += loss_distillation_batch.item()\n",
        "\n",
        "# Вычисление средней дистилляционной потери\n",
        "avg_loss_distillation = loss_distillation_total / num_batches\n",
        "print(avg_loss_distillation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JopP4gFViz_c",
        "outputId": "549365f1-e2aa-48ae-cce7-f7bf1a468e9f"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Distillation:   0%|          | 0/500 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2943: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
            "  warnings.warn(\n",
            "                                                                "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.3548936418374069e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Сравнение качества моделей**"
      ],
      "metadata": {
        "id": "kepYoBsgjCfB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_teacher.eval()\n",
        "model_student.eval()"
      ],
      "metadata": {
        "id": "Wwfn05Uni0Bg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Оценка качества учителя на тестовых данных\n",
        "with torch.no_grad():\n",
        "    logits_teacher_test = []\n",
        "    for i in range(0, len(test_data_enc[\"input_ids\"]), batch_size):\n",
        "        input_ids_batch = torch.tensor(test_data_enc[\"input_ids\"][i:i+batch_size]).to(device)\n",
        "        attention_mask_batch = torch.tensor(test_data_enc[\"attention_mask\"][i:i+batch_size]).to(device)\n",
        "\n",
        "        logits_batch = model_teacher(input_ids_batch, attention_mask=attention_mask_batch).logits\n",
        "        logits_teacher_test.append(logits_batch)\n",
        "\n",
        "    logits_teacher_test = torch.cat(logits_teacher_test, dim=0)\n",
        "\n",
        "    predictions_teacher = torch.argmax(logits_teacher_test, dim=1)\n",
        "    accuracy_teacher = (predictions_teacher == torch.tensor(test_data[\"label\"]).to(device)).float().mean().item()\n",
        "    print(f\"Accuracy Teacher: {accuracy_teacher}\")\n",
        "\n",
        "# Оценка качества ученика на тестовых данных\n",
        "with torch.no_grad():\n",
        "    logits_student_test = []\n",
        "    for i in range(0, len(test_data_enc[\"input_ids\"]), batch_size):\n",
        "        input_ids_batch = torch.tensor(test_data_enc[\"input_ids\"][i:i+batch_size]).to(device)\n",
        "\n",
        "        logits_batch = model_student(input_ids_batch)\n",
        "        logits_student_test.append(logits_batch)\n",
        "\n",
        "    logits_student_test = torch.cat(logits_student_test, dim=0)\n",
        "\n",
        "    predictions_student = torch.argmax(logits_student_test, dim=1)\n",
        "    accuracy_student = (predictions_student == torch.tensor(test_data[\"label\"]).to(device)).float().mean().item()\n",
        "    print(f\"Accuracy Student: {accuracy_student}\")\n",
        "\n",
        "# Оценка качества дистиллированной модели на тестовых данных\n",
        "with torch.no_grad():\n",
        "    logits_distilled_test = []\n",
        "    for i in range(0, len(test_data_enc[\"input_ids\"]), batch_size):\n",
        "        input_ids_batch = torch.tensor(test_data_enc[\"input_ids\"][i:i+batch_size]).to(device)\n",
        "\n",
        "        logits_batch = model_student(input_ids_batch)\n",
        "        logits_distilled_test.append(logits_batch)\n",
        "\n",
        "    logits_distilled_test = torch.cat(logits_distilled_test, dim=0)\n",
        "\n",
        "    predictions_distilled = torch.argmax(logits_distilled_test, dim=1)\n",
        "    accuracy_distilled = (predictions_distilled == torch.tensor(test_data[\"label\"]).to(device)).float().mean().item()\n",
        "    print(f\"Accuracy Distilled: {accuracy_distilled}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kprz1Ac1i0Dv",
        "outputId": "695b1ad8-2479-4a04-ed29-2707369b8799"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy Teacher: 1.0\n",
            "Accuracy Student: 1.0\n",
            "Accuracy Distilled: 1.0\n"
          ]
        }
      ]
    }
  ]
}