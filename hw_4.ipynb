{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DYtsYRInWC75"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n",
        "from transformers import BertTokenizer, BertModel\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from tqdm import tqdm\n",
        "from gensim.models import Word2Vec\n",
        "import gensim.downloader as api\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "from nltk.probability import FreqDist\n",
        "from torchmetrics import F1Score\n",
        "\n",
        "\n",
        "nltk.download('punkt')\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t46v7jbld44s",
        "outputId": "3686073d-8e82-43a0-fad6-d6493b62eeab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2x3hulYK96eI",
        "outputId": "b618be58-e8e8-417c-d8c5-7ca11b8aaca0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fe0e4139670>"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.manual_seed(2023)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "xavXH791ZF4w"
      },
      "outputs": [],
      "source": [
        "#загрузка данных и предобработка\n",
        "fake_df = pd.read_csv('datasets/Fake.csv')\n",
        "fake_df['class'] = 0\n",
        "true_df = pd.read_csv('datasets/True.csv')\n",
        "true_df['class'] = 1\n",
        "\n",
        "\n",
        "true_df[\"text\"] = true_df[\"title\"] + \" \" + true_df[\"text\"]\n",
        "fake_df[\"text\"] = fake_df[\"title\"] + \" \" + fake_df[\"text\"]\n",
        "\n",
        "true_df = true_df.drop([\"subject\", \"date\", \"title\"], axis=1)\n",
        "fake_df = fake_df.drop([\"subject\", \"date\", \"title\"], axis=1)\n",
        "\n",
        "news_df = pd.concat([true_df, fake_df]).reset_index(drop=True)\n",
        "news_df = news_df.sample(frac=1, random_state=2023).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "DoHXQmhUZWyA",
        "outputId": "b7a2d1d8-3ba1-4007-953c-811f4e5ac539"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-7b99f4cf-746e-4552-833d-b332c07f2cfc\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AWESOME RANT By African-American Woman Who’s F...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Meghan McCain: Ted Cruz Is ‘The Thinking Man’...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>China slams Indian minister's visit to dispute...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>OBAMA AND VALERIE JARRETT Finalize Executive A...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Trump Gives Insane Warning On Religious Right...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7b99f4cf-746e-4552-833d-b332c07f2cfc')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7b99f4cf-746e-4552-833d-b332c07f2cfc button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7b99f4cf-746e-4552-833d-b332c07f2cfc');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7874eaec-85b5-4f2d-afe4-40d9332e44fb\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7874eaec-85b5-4f2d-afe4-40d9332e44fb')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7874eaec-85b5-4f2d-afe4-40d9332e44fb button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                                text  class\n",
              "0  AWESOME RANT By African-American Woman Who’s F...      0\n",
              "1   Meghan McCain: Ted Cruz Is ‘The Thinking Man’...      0\n",
              "2  China slams Indian minister's visit to dispute...      1\n",
              "3  OBAMA AND VALERIE JARRETT Finalize Executive A...      0\n",
              "4   Trump Gives Insane Warning On Religious Right...      0"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "news_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1c6Ka3Svc3wE"
      },
      "source": [
        "**Получим эмбеддинги для текстов**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-XU0P1j7cwOr",
        "outputId": "9ecb64da-e4e2-48c8-a5a0-1d47d2870d04"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
          ]
        }
      ],
      "source": [
        "word2vec_model = api.load(\"word2vec-google-news-300\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sDgCzkYKc84o",
        "outputId": "7d535a90-f215-4674-9e2a-cc3a01f0aa0d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 44898/44898 [01:38<00:00, 453.79it/s]\n"
          ]
        }
      ],
      "source": [
        "def text_to_vector(text, model):\n",
        "    words = text.split()\n",
        "    vectorized_words = [model[word] for word in words if word in model]\n",
        "    if vectorized_words:\n",
        "        return np.mean(vectorized_words, axis=0)\n",
        "    else:\n",
        "        return np.zeros(model.vector_size)\n",
        "\n",
        "def pad_batch(batch):\n",
        "    data = [torch.Tensor(item[0]).long() for item in batch]\n",
        "    data = pad_sequence(data)\n",
        "    labels = torch.Tensor([item[1] for item in batch]).long()\n",
        "    return data, labels\n",
        "\n",
        "embeds = np.array([text_to_vector(text, word2vec_model) for text in tqdm(news_df['text'])])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "mTvRqK5n_mfQ"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(news_df['text'].to_numpy(),\n",
        "                                                    news_df['class'].to_numpy(),\n",
        "                                                    test_size=0.2,\n",
        "                                                    random_state=2023,\n",
        "                                                    shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tCace62c7ZUA",
        "outputId": "765c6d13-905c-4f77-ca81-17bc3446cb30"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 44898/44898 [04:25<00:00, 169.28it/s]\n"
          ]
        }
      ],
      "source": [
        "train_corpus = \" \".join(news_df[\"text\"])\n",
        "train_corpus = train_corpus.lower()\n",
        "train_corpus = list(news_df[\"text\"])\n",
        "\n",
        "tokens = []\n",
        "for text in tqdm(train_corpus):\n",
        "  tokens.extend(word_tokenize(text))\n",
        "tokens_filtered = [word for word in tokens if word.isalnum()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "wM_j2lID7ZWb"
      },
      "outputs": [],
      "source": [
        "max_words = 5000\n",
        "dist = FreqDist(tokens_filtered)\n",
        "tokens_filtered_top = [pair[0] for pair in dist.most_common(max_words-1)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "chYaGU7j7ZYx",
        "outputId": "ff1cc077-4eaf-4dc1-d50b-8beb6abf0200"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4999"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vocabulary = {v: k for k, v in dict(enumerate(tokens_filtered_top, 1)).items()}\n",
        "len(vocabulary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "CMiyGvfH-IWm"
      },
      "outputs": [],
      "source": [
        "def text_to_sequence(text, maxlen):\n",
        "    result = []\n",
        "    tokens = word_tokenize(text.lower())\n",
        "    tokens_filtered = [word for word in tokens if word.isalnum()]\n",
        "    for word in tokens_filtered:\n",
        "        if word in vocabulary:\n",
        "            result.append(vocabulary[word])\n",
        "    padding = [0]*(maxlen-len(result))\n",
        "    return padding + result[-maxlen:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_bBYVIKO7ZbQ",
        "outputId": "8c703fa5-4c8b-4246-f02b-84682d940722"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "There are 4912 / 5000 pretrained vectors found.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "def load_pretrained_vectors(word2idx, model):\n",
        "    # Инициализация случайных эмбеддингов\n",
        "    embeddings = np.random.uniform(-0.25, 0.25, (len(word2idx), model.vector_size))\n",
        "    embeddings[word2idx['<pad>']] = np.zeros((model.vector_size,))\n",
        "\n",
        "    count = 0\n",
        "    for word, index in word2idx.items():\n",
        "        if word in model:\n",
        "            embeddings[index] = model[word]\n",
        "            count += 1\n",
        "\n",
        "    print(f\"There are {count} / {len(word2idx)} pretrained vectors found.\")\n",
        "    return embeddings\n",
        "\n",
        "vocabulary['<pad>'] = 0\n",
        "embeddings = load_pretrained_vectors(vocabulary, word2vec_model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s9MTr4eG7ZgH",
        "outputId": "558238e7-97a6-4273-dd29-9ac39f87c26e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(5000, 300)"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "embeddings.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dn1u7qqB7ZiJ"
      },
      "outputs": [],
      "source": [
        "class ConvTextClassifierPretrainedW2V(nn.Module):\n",
        "    def __init__(self, vocab_size=5000, embedding_dim=300, out_channel=128, num_classes=2):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding.from_pretrained(embeddings, freeze=False)\n",
        "        self.conv = nn.Conv1d(embedding_dim, out_channel, kernel_size=3)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.maxpool = nn.MaxPool1d(kernel_size=2)\n",
        "        self.batchnorm = nn.BatchNorm1d(out_channel)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "        self.linear = nn.Linear(out_channel, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        output = self.embedding(x)\n",
        "        output = output.permute(0, 2, 1)  # bs, emb_dim, len\n",
        "        output = self.conv(output)\n",
        "        output = self.relu(output)\n",
        "        output = self.maxpool(output)\n",
        "        output = self.batchnorm(output)\n",
        "        output = output.view(output.size(0), -1)\n",
        "        output = self.dropout(output)\n",
        "        output = self.linear(output)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "QHuhFvHJ9m11"
      },
      "outputs": [],
      "source": [
        "class TextDataWrapper(Dataset):\n",
        "    def __init__(self, data, target=None, transform=None):\n",
        "        self.data = torch.from_numpy(data).long()\n",
        "        if target is not None:\n",
        "            self.target = torch.from_numpy(target).long()\n",
        "        else:\n",
        "          self.target = None\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        x = self.data[index]\n",
        "        y = self.target[index] if self.target is not None else -1\n",
        "\n",
        "        if self.transform:\n",
        "            x = self.transform(x)\n",
        "        return x, y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "12Wy7e2fAwNU"
      },
      "outputs": [],
      "source": [
        "max_len = 40"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M1nYyJWVAjDG",
        "outputId": "2ff0e288-a77e-4648-f54b-641d2ddb7fee"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 35918/35918 [02:16<00:00, 263.71it/s]\n"
          ]
        }
      ],
      "source": [
        "X_train_c = np.array([text_to_sequence(text, max_len) for text in tqdm(X_train)], dtype=np.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11-PClg8A4Iv",
        "outputId": "794b9b8f-0aab-424f-9e56-a3e5d5417595"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 8980/8980 [00:33<00:00, 271.17it/s]\n"
          ]
        }
      ],
      "source": [
        "X_test_c = np.array([text_to_sequence(text, max_len) for text in tqdm(X_test)], dtype=np.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "drlhp0gM7ZkP"
      },
      "outputs": [],
      "source": [
        "model = ConvTextClassifierPretrainedW2V()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S9Q8OOOB7ZmW"
      },
      "outputs": [],
      "source": [
        "batch_size = 256\n",
        "epochs = 10\n",
        "\n",
        "# Переносим модель на GPU, если доступен\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "print(model)\n",
        "print(\"Parameters:\", sum([param.nelement() for param in model.parameters()]))\n",
        "\n",
        "model.train()\n",
        "f1 = F1Score(task=\"binary\").to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "train_dataset = TextDataWrapper(X_train_c, y_train)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "loss_history = []\n",
        "\n",
        "for epoch in range(1, epochs + 1):\n",
        "    print(f\"Train epoch {epoch}/{epochs}\")\n",
        "    temp_loss = []\n",
        "    temp_metrics = []\n",
        "    for i, (data, target) in enumerate(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Переносим данные на GPU\n",
        "        data, target = data.to(device), target.to(device)\n",
        "\n",
        "        output = model(data)\n",
        "\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "        temp_loss.append(loss.float().item())\n",
        "        temp_metrics.append(f1(output.argmax(1), target).item())\n",
        "\n",
        "    epoch_loss = np.array(temp_loss).mean()\n",
        "    epoch_f1 = np.array(temp_metrics).mean()\n",
        "    print(f'Loss: {epoch_loss}, f1 score: {epoch_f1}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "G8ECwm2m7Zp8"
      },
      "outputs": [],
      "source": [
        "def predict(model, data_loader):\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data, _ in data_loader:\n",
        "            data = data.to(device)\n",
        "            output = model(data)\n",
        "            predicted_classes = output.argmax(dim=1)\n",
        "            predictions.extend(predicted_classes.cpu().numpy())\n",
        "\n",
        "    model.train()\n",
        "    return predictions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "DjIxBapfGR6b"
      },
      "outputs": [],
      "source": [
        "batch_size = 256\n",
        "test_dataset = TextDataWrapper(X_test_c, y_test)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "M1qRoDy67Zr6"
      },
      "outputs": [],
      "source": [
        "predictions = predict(model, test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Z1ORtGF7Ztv",
        "outputId": "563f653e-937f-4857-b1a7-37d62358610e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification report for CNN model\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.52      0.52      0.52      4695\n",
            "           1       0.47      0.47      0.47      4285\n",
            "\n",
            "    accuracy                           0.50      8980\n",
            "   macro avg       0.50      0.50      0.50      8980\n",
            "weighted avg       0.50      0.50      0.50      8980\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print('Classification report for CNN model')\n",
        "print(classification_report(y_test, predictions))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "hOKDb5et63K9"
      },
      "outputs": [],
      "source": [
        "class LSTM(nn.Module):\n",
        "    def __init__(self, vocab_size=5000, embedding_dim=300, hidden_dim=128, num_classes=2):\n",
        "        super(LSTM, self).__init__()\n",
        "        self.embedding = nn.Embedding.from_pretrained(embeddings, freeze=False)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=2, batch_first=True, bidirectional=True)\n",
        "        self.fc = nn.Linear(hidden_dim*4, num_classes)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        embedded = self.embedding(x)\n",
        "        lstm_out, _ = self.lstm(embedded)\n",
        "        lstm_out = self.dropout(lstm_out)\n",
        "        avg_pool = torch.mean(lstm_out, 1)\n",
        "        max_pool, _ = torch.max(lstm_out, 1)\n",
        "        concatenated = torch.cat((avg_pool, max_pool), 1)\n",
        "        output = self.fc(concatenated)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "xqb6jH66IgU_"
      },
      "outputs": [],
      "source": [
        "embeddings = torch.tensor(embeddings, dtype=torch.float32)\n",
        "model = LSTM()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C1hmixkvQgAa",
        "outputId": "34e437d5-ca8b-4a39-ec63-cd19f2dd12b9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([5000, 300])"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "embeddings.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "Hy1SAadsdK7y"
      },
      "outputs": [],
      "source": [
        "train_dataset = TextDataWrapper(X_train_c, y_train)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ngAUdp663Nx",
        "outputId": "d57d3a52-249e-41c5-f857-e1bff4452856"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LSTM(\n",
            "  (embedding): Embedding(5000, 300)\n",
            "  (lstm): LSTM(300, 128, num_layers=2, batch_first=True, bidirectional=True)\n",
            "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            ")\n",
            "Parameters: 2336610\n",
            "Train epoch 1/10\n",
            "Loss: 0.23607120942984913, f1 score: 0.8800093140585202\n",
            "Train epoch 2/10\n",
            "Loss: 0.11565913915211427, f1 score: 0.9544384192067681\n",
            "Train epoch 3/10\n",
            "Loss: 0.08457242138683796, f1 score: 0.968553051035455\n",
            "Train epoch 4/10\n",
            "Loss: 0.06392311851711983, f1 score: 0.9766937963506008\n",
            "Train epoch 5/10\n",
            "Loss: 0.04494608222698489, f1 score: 0.9846901111568965\n",
            "Train epoch 6/10\n",
            "Loss: 0.02563950370217786, f1 score: 0.9918507261479155\n",
            "Train epoch 7/10\n",
            "Loss: 0.01971150945264397, f1 score: 0.9930601885132756\n",
            "Train epoch 8/10\n",
            "Loss: 0.013000257683964116, f1 score: 0.9961216745647132\n",
            "Train epoch 9/10\n",
            "Loss: 0.008637847037447603, f1 score: 0.9975270168155643\n",
            "Train epoch 10/10\n",
            "Loss: 0.012514783503778331, f1 score: 0.9957092548093052\n"
          ]
        }
      ],
      "source": [
        "batch_size = 256\n",
        "epochs = 10\n",
        "\n",
        "# Переносим модель на GPU, если доступен\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "print(model)\n",
        "print(\"Parameters:\", sum([param.nelement() for param in model.parameters()]))\n",
        "\n",
        "model.train()\n",
        "f1 = F1Score(task=\"binary\").to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "train_dataset = TextDataWrapper(X_train_c, y_train)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "loss_history = []\n",
        "\n",
        "for epoch in range(1, epochs + 1):\n",
        "    print(f\"Train epoch {epoch}/{epochs}\")\n",
        "    temp_loss = []\n",
        "    temp_metrics = []\n",
        "    for i, (data, target) in enumerate(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Переносим данные на GPU\n",
        "        data, target = data.to(device), target.to(device)\n",
        "\n",
        "        output = model(data)\n",
        "\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "        temp_loss.append(loss.float().item())\n",
        "        temp_metrics.append(f1(output.argmax(1), target).item())\n",
        "\n",
        "    epoch_loss = np.array(temp_loss).mean()\n",
        "    epoch_f1 = np.array(temp_metrics).mean()\n",
        "    print(f'Loss: {epoch_loss}, f1 score: {epoch_f1}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "5X_jVNz-fDQi"
      },
      "outputs": [],
      "source": [
        "predictions = predict(model, test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gG2d1w9K63WO",
        "outputId": "65473de5-5b79-4d63-fb2a-ff1a49a2265e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification report for LSTM model\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.52      0.53      0.52      4695\n",
            "           1       0.48      0.47      0.48      4285\n",
            "\n",
            "    accuracy                           0.50      8980\n",
            "   macro avg       0.50      0.50      0.50      8980\n",
            "weighted avg       0.50      0.50      0.50      8980\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print('Classification report for LSTM model')\n",
        "print(classification_report(y_test, predictions))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
